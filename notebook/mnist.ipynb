{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainData shape: (60000, 28, 28, 1)\n",
      "60000 train samples\n",
      "10000 test samples\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Tegar Imansyah\n",
    "MNIST with tensorflow and keras\n",
    "\n",
    "ref:\n",
    "1. https://github.com/fchollet/keras/blob/master/examples/mnist_cnn.py\n",
    "2. http://www.pyimagesearch.com/2016/08/01/lenet-convolutional-neural-network-in-python/\n",
    "'''\n",
    "\n",
    "from __future__ import print_function\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from net.lenet import LeNet\n",
    "from keras import backend as K\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import keras.preprocessing.image as image\n",
    "\n",
    "\n",
    "batch_size = 128\n",
    "num_classes = 10\n",
    "epochs = 12\n",
    "\n",
    "# input image dimensions\n",
    "img_rows, img_cols = 28, 28\n",
    "\n",
    "# the data, shuffled and split between train and test sets\n",
    "(trainData, trainLabels), (testData, testLabels) = mnist.load_data()\n",
    "\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    trainData = trainData.reshape(trainData.shape[0], 1, img_rows, img_cols)\n",
    "    testData = testData.reshape(testData.shape[0], 1, img_rows, img_cols)\n",
    "    input_shape = (1, img_rows, img_cols)\n",
    "else:\n",
    "    trainData = trainData.reshape(trainData.shape[0], img_rows, img_cols, 1)\n",
    "    testData = testData.reshape(testData.shape[0], img_rows, img_cols, 1)\n",
    "    input_shape = (img_rows, img_cols, 1)\n",
    "\n",
    "trainData = trainData.astype('float32')\n",
    "testData = testData.astype('float32')\n",
    "trainData /= 255.0 # Merubah scaling 0 - 255 menjadi 0 - 1.0\n",
    "testData /= 255.0\n",
    "\n",
    "print('trainData shape:', trainData.shape)\n",
    "print(trainData.shape[0], 'train samples')\n",
    "print(testData.shape[0], 'test samples')\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "trainLabels = keras.utils.to_categorical(trainLabels, num_classes)\n",
    "testLabels = keras.utils.to_categorical(testLabels, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] drawing networks...\n",
      "[INFO] compiling...\n"
     ]
    }
   ],
   "source": [
    "print(\"[INFO] drawing networks...\")\n",
    "model = LeNet.build(input_shape=input_shape, classes=num_classes,\n",
    "    weightsPath=None)\n",
    "\n",
    "print(\"[INFO] compiling...\")\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adadelta(),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] training...\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/12\n",
      "60000/60000 [==============================] - 9s - loss: 0.3442 - acc: 0.8945 - val_loss: 0.0789 - val_acc: 0.9752\n",
      "Epoch 2/12\n",
      "60000/60000 [==============================] - 4s - loss: 0.1179 - acc: 0.9652 - val_loss: 0.0537 - val_acc: 0.9832\n",
      "Epoch 3/12\n",
      "60000/60000 [==============================] - 4s - loss: 0.0885 - acc: 0.9736 - val_loss: 0.0420 - val_acc: 0.9865\n",
      "Epoch 4/12\n",
      "60000/60000 [==============================] - 4s - loss: 0.0733 - acc: 0.9785 - val_loss: 0.0411 - val_acc: 0.9861\n",
      "Epoch 5/12\n",
      "60000/60000 [==============================] - 4s - loss: 0.0650 - acc: 0.9805 - val_loss: 0.0346 - val_acc: 0.9885\n",
      "Epoch 6/12\n",
      "60000/60000 [==============================] - 4s - loss: 0.0581 - acc: 0.9833 - val_loss: 0.0367 - val_acc: 0.9873\n",
      "Epoch 7/12\n",
      "60000/60000 [==============================] - 4s - loss: 0.0514 - acc: 0.9848 - val_loss: 0.0327 - val_acc: 0.9883\n",
      "Epoch 8/12\n",
      "60000/60000 [==============================] - 4s - loss: 0.0483 - acc: 0.9857 - val_loss: 0.0325 - val_acc: 0.9889\n",
      "Epoch 9/12\n",
      "60000/60000 [==============================] - 4s - loss: 0.0432 - acc: 0.9869 - val_loss: 0.0314 - val_acc: 0.9889\n",
      "Epoch 10/12\n",
      "60000/60000 [==============================] - 4s - loss: 0.0417 - acc: 0.9874 - val_loss: 0.0298 - val_acc: 0.9905\n",
      "Epoch 11/12\n",
      "60000/60000 [==============================] - 4s - loss: 0.0402 - acc: 0.9877 - val_loss: 0.0295 - val_acc: 0.9897\n",
      "Epoch 12/12\n",
      "60000/60000 [==============================] - 4s - loss: 0.0376 - acc: 0.9887 - val_loss: 0.0314 - val_acc: 0.9891\n",
      "[INFO] evaluating...\n",
      "Test loss: 0.0314195383097\n",
      "Test accuracy: 0.9891\n"
     ]
    }
   ],
   "source": [
    "print(\"[INFO] training...\")\n",
    "model.fit(trainData, trainLabels,\n",
    "        batch_size=batch_size,\n",
    "        epochs=epochs,\n",
    "        verbose=1,\n",
    "        validation_data=(testData, testLabels))\n",
    "print(\"[INFO] evaluating...\")\n",
    "(loss, accuracy) = model.evaluate(testData, testLabels, verbose=0)\n",
    "print('Test loss:', loss)\n",
    "print('Test accuracy:', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "print(testData[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for i in np.random.choice(np.arange(0, len(testLabels)), size=(10,)):\n",
    "    # classify the digit\n",
    "    probs = model.predict(testData[np.newaxis, i])\n",
    "    print(probs)\n",
    "    prediction = probs.argmax(axis=1)\n",
    "    \n",
    "    # resize the image from a 28 x 28 image to a 96 x 96 image so we\n",
    "    # can better see it\n",
    "    img = image.array_to_img(testData[i] * 255)\n",
    "    plt.imshow(img)\n",
    "    plt.show()\n",
    "    # show the image and prediction\n",
    "    print(\"[INFO] Predicted:\" + str(prediction[0]) + \", Actual: \" + str(np.argmax(testLabels[i])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
