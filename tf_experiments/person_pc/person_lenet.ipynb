{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Tegar Imansyah\n",
    "Lenet with tensorflow and keras\n",
    "\n",
    "ref:\n",
    "1. https://github.com/fchollet/keras/blob/master/examples/mnist_cnn.py\n",
    "2. http://www.pyimagesearch.com/2016/08/01/lenet-convolutional-neural-network-in-python/\n",
    "'''\n",
    "\n",
    "from keras import applications\n",
    "from keras import optimizers\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "import keras.preprocessing.image as image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# dimensions of our images.\n",
    "img_width, img_height = 150, 150\n",
    "\n",
    "train_data_dir = 'data/train'\n",
    "validation_data_dir = 'data/validation'\n",
    "nb_train_samples = 12810+8303\n",
    "nb_validation_samples = 6319+4639\n",
    "epochs = 50\n",
    "batch_size = 16\n",
    "input_shape = (img_width, img_height, 3) # 3 Channel, di belakang karena menggunakan tensorflow's channel_last\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 21113 images belonging to 2 classes.\n",
      "Found 10958 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# prepare data augmentation configuration\n",
    "train_datagen = image.ImageDataGenerator(\n",
    "    rescale=1. / 255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True)\n",
    "\n",
    "test_datagen = image.ImageDataGenerator(rescale=1. / 255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_data_dir,\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='binary')\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "    validation_data_dir,\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] drawing networks...\n",
      "[INFO] compiling...\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_3 (Conv2D)            (None, 148, 148, 32)      896       \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 146, 146, 64)      18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 73, 73, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 73, 73, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 341056)            0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 128)               43655296  \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 43,674,817.0\n",
      "Trainable params: 43,674,817.0\n",
      "Non-trainable params: 0.0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "print(\"[INFO] drawing networks...\")\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=input_shape))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "print(\"[INFO] compiling...\")\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer=optimizers.SGD(lr=1e-4, momentum=0.9),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] training...\n",
      "Epoch 1/50\n",
      "1319/1319 [==============================] - 379s - loss: 0.6094 - acc: 0.6523 - val_loss: 0.5685 - val_acc: 0.7039\n",
      "Epoch 2/50\n",
      "1319/1319 [==============================] - 124s - loss: 0.5427 - acc: 0.7182 - val_loss: 0.5093 - val_acc: 0.7410\n",
      "Epoch 3/50\n",
      "1319/1319 [==============================] - 124s - loss: 0.4865 - acc: 0.7593 - val_loss: 0.4680 - val_acc: 0.7783\n",
      "Epoch 4/50\n",
      "1319/1319 [==============================] - 124s - loss: 0.4552 - acc: 0.7849 - val_loss: 0.4788 - val_acc: 0.7601\n",
      "Epoch 5/50\n",
      "1319/1319 [==============================] - 124s - loss: 0.4352 - acc: 0.8016 - val_loss: 0.4523 - val_acc: 0.7877\n",
      "Epoch 6/50\n",
      "1319/1319 [==============================] - 123s - loss: 0.4193 - acc: 0.8128 - val_loss: 0.4211 - val_acc: 0.8183\n",
      "Epoch 7/50\n",
      "1319/1319 [==============================] - 124s - loss: 0.4071 - acc: 0.8200 - val_loss: 0.4210 - val_acc: 0.8117\n",
      "Epoch 8/50\n",
      "1319/1319 [==============================] - 124s - loss: 0.3945 - acc: 0.8278 - val_loss: 0.4089 - val_acc: 0.8209\n",
      "Epoch 9/50\n",
      "1319/1319 [==============================] - 123s - loss: 0.3807 - acc: 0.8369 - val_loss: 0.3953 - val_acc: 0.8294\n",
      "Epoch 10/50\n",
      "1319/1319 [==============================] - 124s - loss: 0.3669 - acc: 0.8461 - val_loss: 0.4049 - val_acc: 0.8258\n",
      "Epoch 11/50\n",
      "1319/1319 [==============================] - 123s - loss: 0.3596 - acc: 0.8464 - val_loss: 0.3799 - val_acc: 0.8403\n",
      "Epoch 12/50\n",
      " 240/1319 [====>.........................] - ETA: 77s - loss: 0.3583 - acc: 0.8501"
     ]
    }
   ],
   "source": [
    "print(\"[INFO] training...\")\n",
    "# fine-tune the model\n",
    "model.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch=nb_train_samples // batch_size,\n",
    "    epochs=epochs,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=nb_validation_samples // batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main Program Sampai Disini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "millis = int(round(time.time() * 1000))\n",
    "weight_path = 'person_small_' + str(millis) + '.h5'\n",
    "model.save_weights(weight_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "1319/1319 [==============================] - 124s - loss: 0.1940 - acc: 0.9243 - val_loss: 0.2886 - val_acc: 0.8945\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f7b8cfaac10>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch=nb_train_samples // batch_size,\n",
    "    epochs=1,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=nb_validation_samples // batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/validation/neg/victim856_0_5028.jpeg\n",
      "Predict: No Victim, Actual: No Victim\n",
      "Predicted in 0.0619530677795 seconds\n",
      "data/validation/pos/victim508_0_7184.jpeg\n",
      "Predict: No Victim, Actual: Victim\n",
      "Predicted in 0.00343489646912 seconds\n",
      "data/validation/neg/victim686_0_3172.jpeg\n",
      "Predict: No Victim, Actual: No Victim\n",
      "Predicted in 0.00347709655762 seconds\n",
      "data/validation/neg/victim729_0_6296.jpeg\n",
      "Predict: No Victim, Actual: No Victim\n",
      "Predicted in 0.00336313247681 seconds\n",
      "data/validation/neg/victim828_0_8654.jpeg\n",
      "Predict: No Victim, Actual: No Victim\n",
      "Predicted in 0.00329995155334 seconds\n",
      "data/validation/neg/victim828_0_8750.jpeg\n",
      "Predict: No Victim, Actual: No Victim\n",
      "Predicted in 0.00345301628113 seconds\n",
      "data/validation/neg/victim753_0_5525.jpeg\n",
      "Predict: No Victim, Actual: No Victim\n",
      "Predicted in 0.00346612930298 seconds\n",
      "data/validation/pos/victim418_0_6258.jpeg\n",
      "Predict: No Victim, Actual: Victim\n",
      "Predicted in 0.00365614891052 seconds\n",
      "data/validation/pos/victim501_0_2036.jpeg\n",
      "Predict: No Victim, Actual: Victim\n",
      "Predicted in 0.0034818649292 seconds\n"
     ]
    }
   ],
   "source": [
    "def check(probs,answer):\n",
    "    if(probs[0,0] == 0):\n",
    "        print('Predict: No Victim, Actual: ' + answer)\n",
    "    else:\n",
    "        print('Predict: Victim, Actual: ' + answer)\n",
    "        \n",
    "def showtest():  \n",
    "    import os, random\n",
    "    for i in range(9):\n",
    "        if (np.random.randint(1,2+1) == 1):\n",
    "            chosen_file = random.choice(os.listdir(\"data/validation/pos\"))\n",
    "            img_path = 'data/validation/pos/' \n",
    "            img_path+= str(chosen_file)\n",
    "            answer = 'Victim'\n",
    "        else:\n",
    "            chosen_file = random.choice(os.listdir(\"data/validation/neg\"))\n",
    "            img_path = 'data/validation/neg/' \n",
    "            img_path+= str(chosen_file)\n",
    "            answer = 'No Victim'\n",
    "\n",
    "        \n",
    "        img = image.load_img(img_path, target_size=(150,150))\n",
    "        # plt.imshow(img)\n",
    "        # plt.show()\n",
    "        print(img_path)\n",
    "        img = image.img_to_array(img)\n",
    "        img = img.reshape((1,) + img.shape)\n",
    "        start_time = time.time()\n",
    "        probs = model.predict(img)\n",
    "        check(probs, answer)\n",
    "        print('Predicted in %s seconds' % (time.time()-start_time))\n",
    "\n",
    "\n",
    "showtest()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
